{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import requests\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import image as img\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/hp/Desktop/TCS-HumanAI-Submission-AGE-Ethnicity-Gender-Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Face_Recognition.json', 'r') as infile:\n",
    "    # Variable for building our JSON block\n",
    "    json_block = []\n",
    "\n",
    "    for line in infile:\n",
    "        # Add the line to our JSON block\n",
    "        json_block.append(line)\n",
    "        # Check whether we closed our JSON block\n",
    "        if line.startswith('}'):\n",
    "\n",
    "            # Do something with the JSON dictionary\n",
    "            json_dict = json.loads(''.join(json_block))\n",
    "            print(json_dict)\n",
    "\n",
    "            # Start a new block\n",
    "            json_block = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                             | 7/121 [01:06<21:56, 11.55s/it]C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:2655: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [20:25<00:00, 10.13s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(121)):\n",
    "    try:\n",
    "        js = json.loads(json_block[i].replace(\"'\", \"\\\"\"))\n",
    "        image = Image.open(requests.get(js['content'], stream=True).raw)\n",
    "        image = np.asarray(image)\n",
    "        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        for d in js['annotation']:\n",
    "            width = d['imageWidth']\n",
    "            height = d['imageHeight']\n",
    "            x1 = int(width*d['points'][0]['x'])\n",
    "            y1 = int(height*d['points'][0]['y'])\n",
    "            x2 = int(width*d['points'][1]['x'])\n",
    "            y2 = int(height*d['points'][1]['y'])\n",
    "            roi = gray[y1:y2,x1:x2]\n",
    "            s = d['label'][0]\n",
    "            for k in range(1,len(d['label'])):\n",
    "                s = s+\" \"+ d['label'][k]\n",
    "            cv2.imwrite(s+'.jpg',roi)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('./'):\n",
    "    if filename.endswith('.jpg'):\n",
    "        if 'below20' in filename:\n",
    "            shutil.copy(filename,'./dataset/age/below_20/')\n",
    "        if '20_30' in filename:\n",
    "            shutil.copy(filename,'./dataset/age/20-30/')\n",
    "        if '30_40' in filename:\n",
    "            shutil.copy(filename,'./dataset/age/30-40/')\n",
    "        if '40_50' in filename:\n",
    "            shutil.copy(filename,'./dataset/age/40-50/')\n",
    "        if 'above_50' in filename:\n",
    "            shutil.copy(filename,'./dataset/age/above_50/')\n",
    "        if 'Angry' in filename:\n",
    "            shutil.copy(filename,'./dataset/emotions/angry/')\n",
    "        if 'Happy' in filename:\n",
    "            shutil.copy(filename,'./dataset/emotions/happy/')\n",
    "        if 'Neutral' in filename:\n",
    "            shutil.copy(filename,'./dataset/emotions/neutral/')\n",
    "        if 'Sad' in filename:\n",
    "            shutil.copy(filename,'./dataset/emotions/sad/')\n",
    "        if 'Arab' in filename:\n",
    "            shutil.copy(filename,'./dataset/ethnicity/arab/')\n",
    "        if 'Asian' in filename:\n",
    "            shutil.copy(filename,'./dataset/ethnicity/asian/')\n",
    "        if 'Black' in filename:\n",
    "            shutil.copy(filename,'./dataset/ethnicity/black/')\n",
    "        if 'Hispanic' in filename:\n",
    "            shutil.copy(filename,'./dataset/ethnicity/hispanic/')\n",
    "        if 'Indian' in filename:\n",
    "            shutil.copy(filename,'./dataset/ethnicity/indian/')\n",
    "        if 'White' in filename:\n",
    "            shutil.copy(filename,'./dataset/ethnicity/white/')\n",
    "        if 'Female' in filename:\n",
    "            shutil.copy(filename,'./dataset/gender/F/')\n",
    "        if 'Male' in filename:\n",
    "            shutil.copy(filename,'./dataset/gender/M/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train_x = []\n",
    "age_train_y = []\n",
    "\n",
    "age_dict={\n",
    "    'below_20':0,\n",
    "     '20-30':1,\n",
    "    '30-40':2,\n",
    "    '40-50':3,\n",
    "    'above_50':4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in os.listdir('./dataset/age'):\n",
    "    for p in os.listdir('./dataset/age/'+str(item)):\n",
    "        try:\n",
    "            image = keras.preprocessing.image.load_img('./dataset/age/'+str(item)+\"/\"+str(p),target_size=(70,70))\n",
    "            image = keras.preprocessing.image.img_to_array(image)\n",
    "            image = image/255\n",
    "            age_train_x.append(image)\n",
    "            age_train_y.append(age_dict[item])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train_x = np.asarray(age_train_x)\n",
    "age_train_y = np.asarray(age_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76, 70, 70, 3), (76,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_train_x.shape , age_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train_y = keras.utils.to_categorical(age_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train_x, age_train_y = shuffle(age_train_x,age_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0824 20:39:29.343574 10876 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(70, 70, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "W0824 20:39:29.380475 10876 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0824 20:39:29.385429 10876 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0824 20:39:29.413355 10876 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  import sys\n",
      "W0824 20:39:29.487190 10876 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0824 20:39:29.511132 10876 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "age_model = Sequential()\n",
    "\n",
    "#Convolution layer 1\n",
    "age_model.add(Conv2D(32,3,3,input_shape=(70,70,3),activation='relu'))\n",
    "age_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Convolution layer 2\n",
    "age_model.add(Conv2D(64,3,3,activation='relu'))\n",
    "age_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Flattening \n",
    "age_model.add(Flatten())\n",
    "#Feeding into fully Connected layers\n",
    "age_model.add(Dense(128,activation='relu'))\n",
    "age_model.add(Dense(64,activation='relu'))\n",
    "#output layer\n",
    "age_model.add(Dense(age_train_y.shape[1],activation='softmax')) \n",
    "age_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0824 20:39:39.382693 10876 deprecation.py:323] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0824 20:39:39.448516 10876 deprecation_wrapper.py:119] From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 8 samples\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - ETA: 20s - loss: 1.6126 - acc: 0.15 - ETA: 1s - loss: 1.6597 - acc: 0.1719 - 18s 269ms/step - loss: 1.6769 - acc: 0.1618 - val_loss: 1.6049 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.5578 - acc: 0.281 - ETA: 0s - loss: 1.5805 - acc: 0.281 - 0s 2ms/step - loss: 1.5792 - acc: 0.2941 - val_loss: 1.6848 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.5658 - acc: 0.281 - ETA: 0s - loss: 1.5495 - acc: 0.281 - 0s 2ms/step - loss: 1.5579 - acc: 0.2794 - val_loss: 1.6198 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.5112 - acc: 0.281 - ETA: 0s - loss: 1.5110 - acc: 0.343 - 0s 2ms/step - loss: 1.5205 - acc: 0.3529 - val_loss: 1.5571 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.4346 - acc: 0.437 - ETA: 0s - loss: 1.4835 - acc: 0.453 - 0s 2ms/step - loss: 1.4745 - acc: 0.4706 - val_loss: 1.5931 - val_acc: 0.2500\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.4529 - acc: 0.468 - ETA: 0s - loss: 1.4562 - acc: 0.375 - 0s 2ms/step - loss: 1.4421 - acc: 0.3824 - val_loss: 1.6677 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.3455 - acc: 0.562 - ETA: 0s - loss: 1.4100 - acc: 0.531 - 0s 2ms/step - loss: 1.4080 - acc: 0.5294 - val_loss: 1.5543 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.3374 - acc: 0.406 - ETA: 0s - loss: 1.3208 - acc: 0.437 - 0s 2ms/step - loss: 1.3070 - acc: 0.4559 - val_loss: 1.5871 - val_acc: 0.3750\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.2128 - acc: 0.593 - ETA: 0s - loss: 1.2280 - acc: 0.578 - 0s 2ms/step - loss: 1.2183 - acc: 0.5882 - val_loss: 1.7274 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.1903 - acc: 0.437 - ETA: 0s - loss: 1.1394 - acc: 0.468 - 0s 2ms/step - loss: 1.1298 - acc: 0.4853 - val_loss: 1.5299 - val_acc: 0.3750\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0200 - acc: 0.593 - ETA: 0s - loss: 0.9761 - acc: 0.625 - 0s 2ms/step - loss: 0.9709 - acc: 0.6324 - val_loss: 1.6517 - val_acc: 0.3750\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.8805 - acc: 0.562 - ETA: 0s - loss: 0.8505 - acc: 0.640 - 0s 2ms/step - loss: 0.8570 - acc: 0.6324 - val_loss: 2.3112 - val_acc: 0.2500\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.9558 - acc: 0.656 - ETA: 0s - loss: 0.8562 - acc: 0.718 - 0s 2ms/step - loss: 0.8652 - acc: 0.7206 - val_loss: 1.9749 - val_acc: 0.2500\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.5563 - acc: 0.875 - ETA: 0s - loss: 0.6678 - acc: 0.781 - 0s 2ms/step - loss: 0.6985 - acc: 0.7647 - val_loss: 2.5052 - val_acc: 0.2500\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.5879 - acc: 0.812 - ETA: 0s - loss: 0.7687 - acc: 0.656 - 0s 2ms/step - loss: 0.7465 - acc: 0.6618 - val_loss: 2.3238 - val_acc: 0.2500\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.5794 - acc: 0.843 - ETA: 0s - loss: 0.5570 - acc: 0.828 - 0s 2ms/step - loss: 0.5504 - acc: 0.8235 - val_loss: 2.2858 - val_acc: 0.2500\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.5614 - acc: 0.812 - ETA: 0s - loss: 0.5665 - acc: 0.828 - 0s 2ms/step - loss: 0.5428 - acc: 0.8382 - val_loss: 2.2658 - val_acc: 0.2500\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.3443 - acc: 0.937 - ETA: 0s - loss: 0.3960 - acc: 0.890 - 0s 2ms/step - loss: 0.3778 - acc: 0.8971 - val_loss: 2.5554 - val_acc: 0.1250\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.3411 - acc: 0.906 - ETA: 0s - loss: 0.3233 - acc: 0.937 - 0s 2ms/step - loss: 0.3174 - acc: 0.9412 - val_loss: 2.5678 - val_acc: 0.2500\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.3945 - acc: 0.875 - ETA: 0s - loss: 0.2717 - acc: 0.906 - 0s 2ms/step - loss: 0.2578 - acc: 0.9118 - val_loss: 2.6323 - val_acc: 0.2500\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2927 - acc: 0.843 - ETA: 0s - loss: 0.2223 - acc: 0.890 - 0s 2ms/step - loss: 0.2278 - acc: 0.8971 - val_loss: 3.3378 - val_acc: 0.1250\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2237 - acc: 0.937 - ETA: 0s - loss: 0.1798 - acc: 0.937 - 0s 2ms/step - loss: 0.1737 - acc: 0.9412 - val_loss: 3.0626 - val_acc: 0.2500\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1413 - acc: 0.968 - ETA: 0s - loss: 0.1462 - acc: 0.984 - 0s 2ms/step - loss: 0.1716 - acc: 0.9706 - val_loss: 3.4591 - val_acc: 0.2500\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1532 - acc: 0.968 - ETA: 0s - loss: 0.4212 - acc: 0.890 - 0s 2ms/step - loss: 0.4183 - acc: 0.8971 - val_loss: 3.7187 - val_acc: 0.2500\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2628 - acc: 0.875 - ETA: 0s - loss: 0.3869 - acc: 0.890 - 0s 2ms/step - loss: 0.3921 - acc: 0.8824 - val_loss: 3.2792 - val_acc: 0.2500\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2793 - acc: 0.968 - ETA: 0s - loss: 0.2583 - acc: 0.937 - 0s 2ms/step - loss: 0.2471 - acc: 0.9412 - val_loss: 3.2559 - val_acc: 0.2500\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2534 - acc: 0.937 - ETA: 0s - loss: 0.2837 - acc: 0.906 - 0s 2ms/step - loss: 0.2708 - acc: 0.9118 - val_loss: 3.0069 - val_acc: 0.2500\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2041 - acc: 0.906 - ETA: 0s - loss: 0.2278 - acc: 0.906 - 0s 2ms/step - loss: 0.2418 - acc: 0.8971 - val_loss: 3.1063 - val_acc: 0.2500\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2457 - acc: 0.937 - ETA: 0s - loss: 0.2212 - acc: 0.953 - 0s 2ms/step - loss: 0.2123 - acc: 0.9559 - val_loss: 2.8551 - val_acc: 0.2500\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2119 - acc: 0.937 - ETA: 0s - loss: 0.2183 - acc: 0.953 - 0s 2ms/step - loss: 0.2174 - acc: 0.9559 - val_loss: 2.8561 - val_acc: 0.2500\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2134 - acc: 0.968 - ETA: 0s - loss: 0.2317 - acc: 0.968 - 0s 2ms/step - loss: 0.2228 - acc: 0.9706 - val_loss: 3.2796 - val_acc: 0.1250\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.3550 - acc: 0.937 - ETA: 0s - loss: 0.2037 - acc: 0.968 - 0s 2ms/step - loss: 0.1936 - acc: 0.9706 - val_loss: 3.9584 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1325 - acc: 0.968 - ETA: 0s - loss: 0.1395 - acc: 0.953 - 0s 2ms/step - loss: 0.1314 - acc: 0.9559 - val_loss: 3.7662 - val_acc: 0.2500\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0914 - acc: 0.968 - ETA: 0s - loss: 0.0987 - acc: 0.968 - 0s 2ms/step - loss: 0.1495 - acc: 0.9559 - val_loss: 4.0359 - val_acc: 0.2500\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1793 - acc: 0.937 - ETA: 0s - loss: 0.3362 - acc: 0.953 - 0s 2ms/step - loss: 0.3340 - acc: 0.9559 - val_loss: 3.7753 - val_acc: 0.2500\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0699 - acc: 1.000 - ETA: 0s - loss: 0.2665 - acc: 0.968 - 0s 2ms/step - loss: 0.2530 - acc: 0.9706 - val_loss: 2.8996 - val_acc: 0.2500\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.3584 - acc: 0.937 - ETA: 0s - loss: 0.2684 - acc: 0.968 - 0s 2ms/step - loss: 0.2551 - acc: 0.9706 - val_loss: 2.9123 - val_acc: 0.1250\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2259 - acc: 0.968 - ETA: 0s - loss: 0.2558 - acc: 0.968 - 0s 2ms/step - loss: 0.2585 - acc: 0.9706 - val_loss: 2.8461 - val_acc: 0.1250\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2991 - acc: 0.937 - ETA: 0s - loss: 0.1849 - acc: 0.968 - 0s 2ms/step - loss: 0.1743 - acc: 0.9706 - val_loss: 3.2963 - val_acc: 0.2500\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2216 - acc: 0.968 - ETA: 0s - loss: 0.1613 - acc: 0.968 - 0s 2ms/step - loss: 0.1522 - acc: 0.9706 - val_loss: 3.8203 - val_acc: 0.2500\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0214 - acc: 1.000 - ETA: 0s - loss: 0.1623 - acc: 0.968 - 0s 2ms/step - loss: 0.1557 - acc: 0.9706 - val_loss: 4.0114 - val_acc: 0.1250\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1340 - acc: 0.968 - ETA: 0s - loss: 0.1192 - acc: 0.968 - 0s 2ms/step - loss: 0.1129 - acc: 0.9706 - val_loss: 4.4417 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1006 - acc: 0.968 - ETA: 0s - loss: 0.0951 - acc: 0.968 - 0s 2ms/step - loss: 0.0903 - acc: 0.9706 - val_loss: 4.6386 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0531 - acc: 0.968 - ETA: 0s - loss: 0.0514 - acc: 0.984 - 0s 2ms/step - loss: 0.0756 - acc: 0.9706 - val_loss: 4.7678 - val_acc: 0.1250\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0971 - acc: 0.968 - ETA: 0s - loss: 0.1146 - acc: 0.968 - 0s 2ms/step - loss: 0.1083 - acc: 0.9706 - val_loss: 5.2178 - val_acc: 0.1250\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1824 - acc: 0.968 - ETA: 0s - loss: 0.2086 - acc: 0.968 - 0s 2ms/step - loss: 0.1964 - acc: 0.9706 - val_loss: 4.3472 - val_acc: 0.2500\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2115 - acc: 0.968 - ETA: 0s - loss: 0.1187 - acc: 0.984 - 0s 2ms/step - loss: 0.1491 - acc: 0.9706 - val_loss: 3.6969 - val_acc: 0.2500\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0591 - acc: 1.000 - ETA: 0s - loss: 0.0998 - acc: 0.984 - 0s 2ms/step - loss: 0.0964 - acc: 0.9853 - val_loss: 3.5596 - val_acc: 0.1250\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1583 - acc: 0.968 - ETA: 0s - loss: 0.1786 - acc: 0.953 - 0s 2ms/step - loss: 0.1790 - acc: 0.9559 - val_loss: 3.6677 - val_acc: 0.1250\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1003 - acc: 0.968 - ETA: 0s - loss: 0.1369 - acc: 0.968 - 0s 2ms/step - loss: 0.1290 - acc: 0.9706 - val_loss: 4.0444 - val_acc: 0.2500\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0907 - acc: 0.968 - ETA: 0s - loss: 0.0535 - acc: 0.984 - 0s 2ms/step - loss: 0.0974 - acc: 0.9706 - val_loss: 4.6733 - val_acc: 0.1250\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0952 - acc: 0.968 - ETA: 0s - loss: 0.0801 - acc: 0.984 - 0s 2ms/step - loss: 0.0974 - acc: 0.9706 - val_loss: 5.2682 - val_acc: 0.1250\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0978 - acc: 0.968 - ETA: 0s - loss: 0.1111 - acc: 0.968 - 0s 2ms/step - loss: 0.1218 - acc: 0.9559 - val_loss: 4.8860 - val_acc: 0.1250\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0410 - acc: 1.000 - ETA: 0s - loss: 0.0902 - acc: 0.968 - 0s 2ms/step - loss: 0.1358 - acc: 0.9559 - val_loss: 4.3127 - val_acc: 0.1250\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1466 - acc: 0.937 - ETA: 0s - loss: 0.1160 - acc: 0.953 - 0s 2ms/step - loss: 0.1175 - acc: 0.9559 - val_loss: 3.8092 - val_acc: 0.2500\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1211 - acc: 0.937 - ETA: 0s - loss: 0.1023 - acc: 0.953 - 0s 2ms/step - loss: 0.0972 - acc: 0.9559 - val_loss: 3.9207 - val_acc: 0.1250\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0230 - acc: 1.000 - ETA: 0s - loss: 0.0860 - acc: 0.953 - 0s 2ms/step - loss: 0.0813 - acc: 0.9559 - val_loss: 4.3006 - val_acc: 0.1250\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0460 - acc: 0.968 - ETA: 0s - loss: 0.0814 - acc: 0.968 - 0s 2ms/step - loss: 0.0770 - acc: 0.9706 - val_loss: 4.6402 - val_acc: 0.1250\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1264 - acc: 0.937 - ETA: 0s - loss: 0.0786 - acc: 0.968 - 0s 2ms/step - loss: 0.0742 - acc: 0.9706 - val_loss: 4.9649 - val_acc: 0.1250\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0452 - acc: 1.000 - ETA: 0s - loss: 0.0703 - acc: 0.968 - 0s 2ms/step - loss: 0.0664 - acc: 0.9706 - val_loss: 5.3216 - val_acc: 0.2500\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0583 - acc: 0.968 - ETA: 0s - loss: 0.0437 - acc: 0.984 - 0s 2ms/step - loss: 0.0650 - acc: 0.9706 - val_loss: 5.7427 - val_acc: 0.2500\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0734 - acc: 0.968 - ETA: 0s - loss: 0.0732 - acc: 0.968 - 0s 2ms/step - loss: 0.0690 - acc: 0.9706 - val_loss: 6.2936 - val_acc: 0.1250\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1323 - acc: 0.968 - ETA: 0s - loss: 0.1293 - acc: 0.968 - 0s 2ms/step - loss: 0.1217 - acc: 0.9706 - val_loss: 6.4087 - val_acc: 0.1250\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1267 - acc: 0.968 - ETA: 0s - loss: 0.1361 - acc: 0.968 - 0s 2ms/step - loss: 0.1285 - acc: 0.9706 - val_loss: 5.9282 - val_acc: 0.1250\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0166 - acc: 1.000 - ETA: 0s - loss: 0.0478 - acc: 0.984 - 0s 2ms/step - loss: 0.0893 - acc: 0.9706 - val_loss: 5.1412 - val_acc: 0.2500\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1257 - acc: 0.937 - ETA: 0s - loss: 0.0657 - acc: 0.968 - 0s 2ms/step - loss: 0.0647 - acc: 0.9706 - val_loss: 4.5002 - val_acc: 0.2500\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1079 - acc: 0.968 - ETA: 0s - loss: 0.0687 - acc: 0.984 - 0s 2ms/step - loss: 0.0957 - acc: 0.9706 - val_loss: 4.2167 - val_acc: 0.2500\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0839 - acc: 0.968 - ETA: 0s - loss: 0.1173 - acc: 0.968 - 0s 2ms/step - loss: 0.1136 - acc: 0.9706 - val_loss: 4.0181 - val_acc: 0.2500\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0542 - acc: 1.000 - ETA: 0s - loss: 0.1108 - acc: 0.968 - 0s 2ms/step - loss: 0.1074 - acc: 0.9706 - val_loss: 4.1132 - val_acc: 0.1250\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0897 - acc: 0.968 - ETA: 0s - loss: 0.0990 - acc: 0.968 - 0s 2ms/step - loss: 0.0956 - acc: 0.9706 - val_loss: 4.4925 - val_acc: 0.2500\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0214 - acc: 1.000 - ETA: 0s - loss: 0.0751 - acc: 0.984 - 0s 2ms/step - loss: 0.0853 - acc: 0.9706 - val_loss: 5.1127 - val_acc: 0.2500\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0112 - acc: 1.000 - ETA: 0s - loss: 0.0826 - acc: 0.968 - 0s 2ms/step - loss: 0.0778 - acc: 0.9706 - val_loss: 5.8305 - val_acc: 0.1250\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1466 - acc: 0.937 - ETA: 0s - loss: 0.0863 - acc: 0.968 - 0s 2ms/step - loss: 0.0813 - acc: 0.9706 - val_loss: 6.1684 - val_acc: 0.1250\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0874 - acc: 0.968 - ETA: 0s - loss: 0.0918 - acc: 0.968 - 0s 2ms/step - loss: 0.0871 - acc: 0.9706 - val_loss: 6.1480 - val_acc: 0.1250\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0895 - acc: 0.968 - ETA: 0s - loss: 0.0824 - acc: 0.968 - 0s 2ms/step - loss: 0.0776 - acc: 0.9706 - val_loss: 6.0424 - val_acc: 0.1250\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0534 - acc: 0.968 - ETA: 0s - loss: 0.0707 - acc: 0.968 - 0s 2ms/step - loss: 0.0668 - acc: 0.9706 - val_loss: 5.8999 - val_acc: 0.1250\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0119 - acc: 1.000 - ETA: 0s - loss: 0.0607 - acc: 0.968 - 0s 2ms/step - loss: 0.0571 - acc: 0.9706 - val_loss: 5.7399 - val_acc: 0.1250\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0027 - acc: 1.000 - ETA: 0s - loss: 0.0577 - acc: 0.968 - 0s 2ms/step - loss: 0.0545 - acc: 0.9706 - val_loss: 5.6263 - val_acc: 0.1250\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - ETA: 0s - loss: 0.0085 - acc: 1.000 - ETA: 0s - loss: 0.0423 - acc: 0.968 - 0s 2ms/step - loss: 0.0546 - acc: 0.9559 - val_loss: 5.4779 - val_acc: 0.1250\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1177 - acc: 0.937 - ETA: 0s - loss: 0.0598 - acc: 0.968 - 0s 2ms/step - loss: 0.0566 - acc: 0.9706 - val_loss: 5.2132 - val_acc: 0.1250\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0703 - acc: 0.968 - ETA: 0s - loss: 0.0789 - acc: 0.968 - 0s 2ms/step - loss: 0.0743 - acc: 0.9706 - val_loss: 5.1204 - val_acc: 0.1250\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0113 - acc: 1.000 - ETA: 0s - loss: 0.0870 - acc: 0.968 - 0s 2ms/step - loss: 0.0819 - acc: 0.9706 - val_loss: 5.1086 - val_acc: 0.1250\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0830 - acc: 0.968 - ETA: 0s - loss: 0.0801 - acc: 0.968 - 0s 2ms/step - loss: 0.0755 - acc: 0.9706 - val_loss: 5.1381 - val_acc: 0.1250\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1362 - acc: 0.937 - ETA: 0s - loss: 0.0707 - acc: 0.968 - 0s 2ms/step - loss: 0.0666 - acc: 0.9706 - val_loss: 5.1759 - val_acc: 0.1250\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0607 - acc: 0.968 - 0s 2ms/step - loss: 0.0574 - acc: 0.9706 - val_loss: 5.2313 - val_acc: 0.1250\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0767 - acc: 0.968 - ETA: 0s - loss: 0.0582 - acc: 0.968 - 0s 2ms/step - loss: 0.0551 - acc: 0.9706 - val_loss: 5.3185 - val_acc: 0.1250\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0505 - acc: 0.968 - ETA: 0s - loss: 0.0580 - acc: 0.968 - 0s 2ms/step - loss: 0.0546 - acc: 0.9706 - val_loss: 5.4336 - val_acc: 0.1250\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0813 - acc: 0.937 - ETA: 0s - loss: 0.0567 - acc: 0.968 - 0s 2ms/step - loss: 0.0535 - acc: 0.9706 - val_loss: 5.5421 - val_acc: 0.1250\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0424 - acc: 0.968 - ETA: 0s - loss: 0.0559 - acc: 0.968 - 0s 2ms/step - loss: 0.0527 - acc: 0.9706 - val_loss: 5.6427 - val_acc: 0.1250\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1103 - acc: 0.937 - ETA: 0s - loss: 0.0559 - acc: 0.968 - 0s 2ms/step - loss: 0.0526 - acc: 0.9706 - val_loss: 5.7297 - val_acc: 0.1250\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0173 - acc: 0.984 - 0s 2ms/step - loss: 0.0531 - acc: 0.9706 - val_loss: 5.7650 - val_acc: 0.1250\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0656 - acc: 0.968 - ETA: 0s - loss: 0.0343 - acc: 0.984 - 0s 2ms/step - loss: 0.0620 - acc: 0.9706 - val_loss: 5.7033 - val_acc: 0.1250\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0563 - acc: 0.968 - 0s 2ms/step - loss: 0.0530 - acc: 0.9706 - val_loss: 5.6022 - val_acc: 0.1250\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0450 - acc: 0.968 - ETA: 0s - loss: 0.0574 - acc: 0.968 - 0s 2ms/step - loss: 0.0541 - acc: 0.9706 - val_loss: 5.5663 - val_acc: 0.1250\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0483 - acc: 0.968 - ETA: 0s - loss: 0.0555 - acc: 0.968 - 0s 2ms/step - loss: 0.0524 - acc: 0.9706 - val_loss: 5.5709 - val_acc: 0.1250\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1124 - acc: 0.937 - ETA: 0s - loss: 0.0567 - acc: 0.968 - 0s 2ms/step - loss: 0.0534 - acc: 0.9706 - val_loss: 5.6119 - val_acc: 0.1250\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0812 - acc: 0.968 - ETA: 0s - loss: 0.0578 - acc: 0.968 - 0s 2ms/step - loss: 0.0544 - acc: 0.9706 - val_loss: 5.6646 - val_acc: 0.1250\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0339 - acc: 0.968 - ETA: 0s - loss: 0.0567 - acc: 0.968 - 0s 2ms/step - loss: 0.0534 - acc: 0.9706 - val_loss: 5.7019 - val_acc: 0.1250\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0601 - acc: 0.968 - ETA: 0s - loss: 0.0557 - acc: 0.968 - 0s 2ms/step - loss: 0.0526 - acc: 0.9706 - val_loss: 5.7505 - val_acc: 0.1250\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0296 - acc: 1.000 - ETA: 0s - loss: 0.0375 - acc: 0.984 - 0s 2ms/step - loss: 0.0524 - acc: 0.9706 - val_loss: 5.7699 - val_acc: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a200a2fc88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_model.fit(age_train_x,age_train_y,epochs=100,batch_size=32,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_model.save('age_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_train_x = []\n",
    "gender_train_y=[]\n",
    "\n",
    "gender_dict = {\n",
    "    'M':0,\n",
    "    'F':1\n",
    "}\n",
    "\n",
    "for item in os.listdir('./dataset/gender'):\n",
    "    for p in os.listdir('./dataset/gender/'+str(item)):\n",
    "        try:\n",
    "            image = keras.preprocessing.image.load_img('./dataset/gender/'+str(item)+\"/\"+str(p),target_size=(70,70))\n",
    "            image = keras.preprocessing.image.img_to_array(image)\n",
    "            image = image/255\n",
    "            gender_train_x.append(image)\n",
    "            gender_train_y.append(gender_dict[item])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "gender_train_x = np.asarray(gender_train_x)\n",
    "gender_train_y = np.asarray(gender_train_y)\n",
    "\n",
    "gender_train_x, gender_train_y = shuffle(gender_train_x,gender_train_y)\n",
    "\n",
    "gender_train_y=keras.utils.to_categorical(gender_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(70, 70, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "gender_model = Sequential()\n",
    "\n",
    "#Convolution layer 1\n",
    "gender_model.add(Conv2D(32,3,3,input_shape=(70,70,3),activation='relu'))\n",
    "gender_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Convolution layer 2\n",
    "gender_model.add(Conv2D(64,3,3,activation='relu'))\n",
    "gender_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Flattening \n",
    "gender_model.add(Flatten())\n",
    "#Feeding into fully Connected layers\n",
    "gender_model.add(Dense(128,activation='relu'))\n",
    "gender_model.add(Dense(64,activation='relu'))\n",
    "#output layer\n",
    "gender_model.add(Dense(2,activation='softmax')) \n",
    "gender_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 8 samples\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6940 - acc: 0.531 - 1s 14ms/step - loss: 0.6936 - acc: 0.5625 - val_loss: 0.5655 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1414 - acc: 0.406 - 0s 2ms/step - loss: 0.9139 - acc: 0.4375 - val_loss: 0.9741 - val_acc: 0.2500\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8052 - acc: 0.375 - 0s 2ms/step - loss: 0.7002 - acc: 0.5312 - val_loss: 0.8127 - val_acc: 0.2500\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6891 - acc: 0.437 - 0s 2ms/step - loss: 0.6594 - acc: 0.5312 - val_loss: 0.7557 - val_acc: 0.2500\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6222 - acc: 0.656 - 0s 2ms/step - loss: 0.6400 - acc: 0.5469 - val_loss: 0.7567 - val_acc: 0.3750\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5969 - acc: 0.687 - 0s 2ms/step - loss: 0.6107 - acc: 0.7031 - val_loss: 0.6977 - val_acc: 0.6250\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5696 - acc: 0.937 - 0s 2ms/step - loss: 0.5864 - acc: 0.7656 - val_loss: 0.7284 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5332 - acc: 0.937 - 0s 2ms/step - loss: 0.5302 - acc: 0.8438 - val_loss: 0.6829 - val_acc: 0.6250\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4824 - acc: 0.937 - 0s 2ms/step - loss: 0.4798 - acc: 0.9375 - val_loss: 0.7979 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4047 - acc: 0.875 - 0s 2ms/step - loss: 0.4428 - acc: 0.8125 - val_loss: 0.6528 - val_acc: 0.6250\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3696 - acc: 0.968 - 0s 2ms/step - loss: 0.3915 - acc: 0.9062 - val_loss: 0.8408 - val_acc: 0.6250\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3641 - acc: 0.843 - 0s 2ms/step - loss: 0.3207 - acc: 0.8906 - val_loss: 0.8609 - val_acc: 0.6250\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.2997 - acc: 0.906 - 0s 2ms/step - loss: 0.2564 - acc: 0.9219 - val_loss: 0.6931 - val_acc: 0.6250\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.2788 - acc: 0.906 - 0s 2ms/step - loss: 0.2334 - acc: 0.9531 - val_loss: 0.9631 - val_acc: 0.6250\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.1772 - acc: 1.000 - 0s 2ms/step - loss: 0.1908 - acc: 0.9531 - val_loss: 0.8121 - val_acc: 0.6250\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.1537 - acc: 0.968 - 0s 2ms/step - loss: 0.1488 - acc: 0.9531 - val_loss: 0.9038 - val_acc: 0.7500\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0807 - acc: 1.000 - 0s 2ms/step - loss: 0.0948 - acc: 1.0000 - val_loss: 0.9540 - val_acc: 0.7500\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0847 - acc: 1.000 - 0s 2ms/step - loss: 0.0667 - acc: 1.0000 - val_loss: 0.9506 - val_acc: 0.6250\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0661 - acc: 1.000 - 0s 2ms/step - loss: 0.0525 - acc: 1.0000 - val_loss: 1.0341 - val_acc: 0.7500\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0362 - acc: 1.000 - 0s 2ms/step - loss: 0.0346 - acc: 1.0000 - val_loss: 1.1134 - val_acc: 0.6250\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0171 - acc: 1.000 - 0s 2ms/step - loss: 0.0230 - acc: 1.0000 - val_loss: 1.2455 - val_acc: 0.6250\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0173 - acc: 1.000 - 0s 2ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.3573 - val_acc: 0.6250\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0097 - acc: 1.000 - 0s 2ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.4613 - val_acc: 0.6250\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0072 - acc: 1.000 - 0s 2ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 1.5733 - val_acc: 0.6250\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.000 - 0s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.6167 - val_acc: 0.6250\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0039 - acc: 1.000 - 0s 2ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.6221 - val_acc: 0.6250\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - 0s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.6599 - val_acc: 0.6250\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.7408 - val_acc: 0.6250\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 8.9804e-04 - acc: 1.000 - 0s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.8452 - val_acc: 0.6250\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.4043e-04 - acc: 1.000 - 0s 2ms/step - loss: 8.0844e-04 - acc: 1.0000 - val_loss: 1.9531 - val_acc: 0.6250\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.9784e-04 - acc: 1.000 - 0s 2ms/step - loss: 6.6002e-04 - acc: 1.0000 - val_loss: 2.0171 - val_acc: 0.6250\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.9083e-04 - acc: 1.000 - 0s 2ms/step - loss: 5.8055e-04 - acc: 1.0000 - val_loss: 2.0578 - val_acc: 0.6250\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.6993e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.7016e-04 - acc: 1.0000 - val_loss: 2.0777 - val_acc: 0.6250\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.8029e-04 - acc: 1.000 - 0s 2ms/step - loss: 3.7655e-04 - acc: 1.0000 - val_loss: 2.0951 - val_acc: 0.6250\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.7675e-04 - acc: 1.000 - 0s 2ms/step - loss: 3.3737e-04 - acc: 1.0000 - val_loss: 2.1171 - val_acc: 0.6250\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.0583e-04 - acc: 1.000 - 0s 2ms/step - loss: 3.0994e-04 - acc: 1.0000 - val_loss: 2.1401 - val_acc: 0.6250\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.0072e-04 - acc: 1.000 - 0s 2ms/step - loss: 2.7251e-04 - acc: 1.0000 - val_loss: 2.1636 - val_acc: 0.6250\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.5843e-04 - acc: 1.000 - 0s 2ms/step - loss: 2.3921e-04 - acc: 1.0000 - val_loss: 2.1880 - val_acc: 0.6250\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.8702e-04 - acc: 1.000 - 0s 2ms/step - loss: 2.1248e-04 - acc: 1.0000 - val_loss: 2.2076 - val_acc: 0.6250\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.9142e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.9691e-04 - acc: 1.0000 - val_loss: 2.2216 - val_acc: 0.6250\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.5131e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.8598e-04 - acc: 1.0000 - val_loss: 2.2314 - val_acc: 0.6250\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6145e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.7430e-04 - acc: 1.0000 - val_loss: 2.2364 - val_acc: 0.6250\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7514e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.6122e-04 - acc: 1.0000 - val_loss: 2.2398 - val_acc: 0.6250\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6336e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.5233e-04 - acc: 1.0000 - val_loss: 2.2422 - val_acc: 0.6250\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6944e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.4452e-04 - acc: 1.0000 - val_loss: 2.2459 - val_acc: 0.6250\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 9.3414e-05 - acc: 1.000 - 0s 2ms/step - loss: 1.4037e-04 - acc: 1.0000 - val_loss: 2.2515 - val_acc: 0.6250\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2382e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.3476e-04 - acc: 1.0000 - val_loss: 2.2577 - val_acc: 0.6250\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1213e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.2892e-04 - acc: 1.0000 - val_loss: 2.2644 - val_acc: 0.6250\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1056e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.2326e-04 - acc: 1.0000 - val_loss: 2.2701 - val_acc: 0.6250\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 8.9512e-05 - acc: 1.000 - 0s 2ms/step - loss: 1.1775e-04 - acc: 1.0000 - val_loss: 2.2769 - val_acc: 0.6250\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0759e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.1380e-04 - acc: 1.0000 - val_loss: 2.2823 - val_acc: 0.6250\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4016e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.1110e-04 - acc: 1.0000 - val_loss: 2.2870 - val_acc: 0.6250\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0985e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.0799e-04 - acc: 1.0000 - val_loss: 2.2918 - val_acc: 0.6250\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0851e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.0423e-04 - acc: 1.0000 - val_loss: 2.2946 - val_acc: 0.6250\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1403e-04 - acc: 1.000 - 0s 2ms/step - loss: 1.0058e-04 - acc: 1.0000 - val_loss: 2.2969 - val_acc: 0.6250\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 8.7574e-05 - acc: 1.000 - 0s 2ms/step - loss: 9.6578e-05 - acc: 1.0000 - val_loss: 2.2999 - val_acc: 0.6250\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1328e-04 - acc: 1.000 - 0s 2ms/step - loss: 9.3696e-05 - acc: 1.0000 - val_loss: 2.3057 - val_acc: 0.6250\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 8.4254e-05 - acc: 1.000 - 0s 2ms/step - loss: 9.0728e-05 - acc: 1.0000 - val_loss: 2.3098 - val_acc: 0.6250\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 7.4688e-05 - acc: 1.000 - 0s 2ms/step - loss: 8.7968e-05 - acc: 1.0000 - val_loss: 2.3135 - val_acc: 0.6250\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 9.3337e-05 - acc: 1.000 - 0s 2ms/step - loss: 8.5495e-05 - acc: 1.0000 - val_loss: 2.3184 - val_acc: 0.6250\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 8.1561e-05 - acc: 1.000 - 0s 2ms/step - loss: 8.2613e-05 - acc: 1.0000 - val_loss: 2.3225 - val_acc: 0.6250\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.6134e-05 - acc: 1.000 - 0s 2ms/step - loss: 7.9850e-05 - acc: 1.0000 - val_loss: 2.3256 - val_acc: 0.6250\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.2623e-05 - acc: 1.000 - 0s 2ms/step - loss: 7.7370e-05 - acc: 1.0000 - val_loss: 2.3297 - val_acc: 0.6250\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 8.5842e-05 - acc: 1.000 - 0s 2ms/step - loss: 7.5215e-05 - acc: 1.0000 - val_loss: 2.3342 - val_acc: 0.6250\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 9.6084e-05 - acc: 1.000 - 0s 2ms/step - loss: 7.2889e-05 - acc: 1.0000 - val_loss: 2.3369 - val_acc: 0.6250\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.6314e-05 - acc: 1.000 - 0s 2ms/step - loss: 7.0699e-05 - acc: 1.0000 - val_loss: 2.3404 - val_acc: 0.6250\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 8.1671e-05 - acc: 1.000 - 0s 2ms/step - loss: 6.8608e-05 - acc: 1.0000 - val_loss: 2.3427 - val_acc: 0.6250\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.7218e-05 - acc: 1.000 - 0s 2ms/step - loss: 6.6240e-05 - acc: 1.0000 - val_loss: 2.3447 - val_acc: 0.6250\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 7.2974e-05 - acc: 1.000 - 0s 2ms/step - loss: 6.4353e-05 - acc: 1.0000 - val_loss: 2.3465 - val_acc: 0.6250\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.4495e-05 - acc: 1.000 - 0s 2ms/step - loss: 6.2621e-05 - acc: 1.0000 - val_loss: 2.3475 - val_acc: 0.6250\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.6507e-05 - acc: 1.000 - 0s 2ms/step - loss: 6.0841e-05 - acc: 1.0000 - val_loss: 2.3480 - val_acc: 0.6250\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.8221e-05 - acc: 1.000 - 0s 2ms/step - loss: 5.8840e-05 - acc: 1.0000 - val_loss: 2.3503 - val_acc: 0.6250\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 7.6225e-05 - acc: 1.000 - 0s 2ms/step - loss: 5.6927e-05 - acc: 1.0000 - val_loss: 2.3546 - val_acc: 0.6250\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.4108e-05 - acc: 1.000 - 0s 2ms/step - loss: 5.5254e-05 - acc: 1.0000 - val_loss: 2.3578 - val_acc: 0.6250\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.9593e-05 - acc: 1.000 - 0s 2ms/step - loss: 5.3480e-05 - acc: 1.0000 - val_loss: 2.3613 - val_acc: 0.6250\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.9881e-05 - acc: 1.000 - 0s 2ms/step - loss: 5.1885e-05 - acc: 1.0000 - val_loss: 2.3652 - val_acc: 0.6250\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.8221e-05 - acc: 1.000 - 0s 2ms/step - loss: 5.0075e-05 - acc: 1.0000 - val_loss: 2.3689 - val_acc: 0.6250\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.5217e-05 - acc: 1.000 - 0s 2ms/step - loss: 4.8545e-05 - acc: 1.0000 - val_loss: 2.3715 - val_acc: 0.6250\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.5979e-05 - acc: 1.000 - 0s 2ms/step - loss: 4.6993e-05 - acc: 1.0000 - val_loss: 2.3747 - val_acc: 0.6250\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.5383e-05 - acc: 1.000 - 0s 2ms/step - loss: 4.5554e-05 - acc: 1.0000 - val_loss: 2.3784 - val_acc: 0.6250\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.9945e-05 - acc: 1.000 - 0s 2ms/step - loss: 4.4179e-05 - acc: 1.0000 - val_loss: 2.3833 - val_acc: 0.6250\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.0558e-05 - acc: 1.000 - 0s 2ms/step - loss: 4.2965e-05 - acc: 1.0000 - val_loss: 2.3871 - val_acc: 0.6250\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.9276e-05 - acc: 1.000 - 0s 2ms/step - loss: 4.1721e-05 - acc: 1.0000 - val_loss: 2.3925 - val_acc: 0.6250\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.2614e-05 - acc: 1.000 - 0s 2ms/step - loss: 4.0100e-05 - acc: 1.0000 - val_loss: 2.3982 - val_acc: 0.6250\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.8263e-05 - acc: 1.000 - 0s 2ms/step - loss: 3.8817e-05 - acc: 1.0000 - val_loss: 2.4034 - val_acc: 0.6250\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.1180e-05 - acc: 1.000 - 0s 2ms/step - loss: 3.7661e-05 - acc: 1.0000 - val_loss: 2.4075 - val_acc: 0.6250\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.0328e-05 - acc: 1.000 - 0s 2ms/step - loss: 3.6493e-05 - acc: 1.0000 - val_loss: 2.4131 - val_acc: 0.6250\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.6404e-05 - acc: 1.000 - 0s 2ms/step - loss: 3.5465e-05 - acc: 1.0000 - val_loss: 2.4180 - val_acc: 0.6250\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.0483e-05 - acc: 1.000 - 0s 2ms/step - loss: 3.4260e-05 - acc: 1.0000 - val_loss: 2.4220 - val_acc: 0.6250\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.4490e-05 - acc: 1.000 - 0s 2ms/step - loss: 3.3074e-05 - acc: 1.0000 - val_loss: 2.4240 - val_acc: 0.6250\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.3972e-05 - acc: 1.000 - 0s 2ms/step - loss: 3.2073e-05 - acc: 1.0000 - val_loss: 2.4283 - val_acc: 0.6250\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.3935e-05 - acc: 1.000 - 0s 2ms/step - loss: 3.1250e-05 - acc: 1.0000 - val_loss: 2.4332 - val_acc: 0.6250\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.9890e-05 - acc: 1.000 - 0s 2ms/step - loss: 3.0370e-05 - acc: 1.0000 - val_loss: 2.4366 - val_acc: 0.6250\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 0s - loss: 3.1472e-05 - acc: 1.000 - 0s 2ms/step - loss: 2.9369e-05 - acc: 1.0000 - val_loss: 2.4409 - val_acc: 0.6250\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.6181e-05 - acc: 1.000 - 0s 2ms/step - loss: 2.8460e-05 - acc: 1.0000 - val_loss: 2.4451 - val_acc: 0.6250\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.2778e-05 - acc: 1.000 - 0s 2ms/step - loss: 2.7666e-05 - acc: 1.0000 - val_loss: 2.4507 - val_acc: 0.6250\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.2517e-05 - acc: 1.000 - 0s 2ms/step - loss: 2.6853e-05 - acc: 1.0000 - val_loss: 2.4533 - val_acc: 0.6250\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.0232e-05 - acc: 1.000 - 0s 2ms/step - loss: 2.6111e-05 - acc: 1.0000 - val_loss: 2.4567 - val_acc: 0.6250\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.7443e-05 - acc: 1.000 - 0s 2ms/step - loss: 2.5328e-05 - acc: 1.0000 - val_loss: 2.4569 - val_acc: 0.6250\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.2663e-05 - acc: 1.000 - 0s 2ms/step - loss: 2.4575e-05 - acc: 1.0000 - val_loss: 2.4567 - val_acc: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a202fc8b38>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_model.fit(gender_train_x,gender_train_y,epochs=100,batch_size=32,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_model.save('gender_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_dict={\n",
    "    'arab':0,\n",
    "    'asian':1,\n",
    "    'black':2,\n",
    "    'hispanic':3,\n",
    "    'indian':4,\n",
    "    'white':5\n",
    "}\n",
    "\n",
    "ethnicity_train_x = []\n",
    "ethnicity_train_y=[]\n",
    "\n",
    "for item in os.listdir('./dataset/ethnicity'):\n",
    "    for p in os.listdir('./dataset/ethnicity/'+str(item)):\n",
    "        try:\n",
    "            image = keras.preprocessing.image.load_img('./dataset/ethnicity/'+str(item)+\"/\"+str(p),target_size=(70,70))\n",
    "            image = keras.preprocessing.image.img_to_array(image)\n",
    "            image = image/255\n",
    "            ethnicity_train_x.append(image)\n",
    "            ethnicity_train_y.append(ethnicity_dict[item])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "ethnicity_train_x = np.asarray(ethnicity_train_x)\n",
    "ethnicity_train_y = np.asarray(ethnicity_train_y)\n",
    "\n",
    "ethnicity_train_y=keras.utils.to_categorical(ethnicity_train_y)\n",
    "\n",
    "ethnicity_train_x, ethnicity_train_y = shuffle(ethnicity_train_x,ethnicity_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(70, 70, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "ethnicity_model = Sequential()\n",
    "\n",
    "#Convolution layer 1\n",
    "ethnicity_model.add(Conv2D(32,3,3,input_shape=(70,70,3),activation='relu'))\n",
    "ethnicity_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Convolution layer 2\n",
    "ethnicity_model.add(Conv2D(64,3,3,activation='relu'))\n",
    "ethnicity_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Flattening \n",
    "ethnicity_model.add(Flatten())\n",
    "#Feeding into fully Connected layers\n",
    "ethnicity_model.add(Dense(128,activation='relu'))\n",
    "ethnicity_model.add(Dense(64,activation='relu'))\n",
    "#output layer\n",
    "ethnicity_model.add(Dense(ethnicity_train_y.shape[1],activation='softmax')) \n",
    "ethnicity_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 8 samples\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7839 - acc: 0.250 - 1s 15ms/step - loss: 1.6573 - acc: 0.2188 - val_loss: 1.9830 - val_acc: 0.3750\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.5640 - acc: 0.500 - 0s 2ms/step - loss: 1.5193 - acc: 0.4219 - val_loss: 1.5557 - val_acc: 0.3750\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2933 - acc: 0.593 - 0s 2ms/step - loss: 1.3880 - acc: 0.5312 - val_loss: 1.5828 - val_acc: 0.2500\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2492 - acc: 0.593 - 0s 2ms/step - loss: 1.3078 - acc: 0.5469 - val_loss: 1.7127 - val_acc: 0.3750\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2869 - acc: 0.500 - 0s 2ms/step - loss: 1.1802 - acc: 0.5469 - val_loss: 1.7862 - val_acc: 0.3750\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0113 - acc: 0.593 - 0s 2ms/step - loss: 1.0833 - acc: 0.5938 - val_loss: 1.7883 - val_acc: 0.2500\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9167 - acc: 0.750 - 0s 2ms/step - loss: 0.9729 - acc: 0.6719 - val_loss: 1.9319 - val_acc: 0.3750\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8851 - acc: 0.781 - 0s 2ms/step - loss: 0.8392 - acc: 0.7344 - val_loss: 1.8979 - val_acc: 0.2500\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7858 - acc: 0.781 - 0s 2ms/step - loss: 0.7616 - acc: 0.7344 - val_loss: 2.2020 - val_acc: 0.3750\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5592 - acc: 0.906 - 0s 2ms/step - loss: 0.6021 - acc: 0.8438 - val_loss: 2.0850 - val_acc: 0.2500\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6549 - acc: 0.781 - 0s 2ms/step - loss: 0.5653 - acc: 0.8125 - val_loss: 2.6571 - val_acc: 0.3750\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4798 - acc: 0.875 - 0s 2ms/step - loss: 0.4355 - acc: 0.8438 - val_loss: 2.5294 - val_acc: 0.2500\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4428 - acc: 0.843 - 0s 2ms/step - loss: 0.3782 - acc: 0.8906 - val_loss: 2.4738 - val_acc: 0.3750\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4203 - acc: 0.875 - 0s 2ms/step - loss: 0.3227 - acc: 0.9219 - val_loss: 2.9970 - val_acc: 0.3750\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.2320 - acc: 0.937 - 0s 2ms/step - loss: 0.2545 - acc: 0.9219 - val_loss: 2.8679 - val_acc: 0.3750\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.2915 - acc: 0.937 - 0s 2ms/step - loss: 0.2075 - acc: 0.9531 - val_loss: 3.0870 - val_acc: 0.3750\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.1903 - acc: 0.937 - 0s 2ms/step - loss: 0.1682 - acc: 0.9688 - val_loss: 3.4908 - val_acc: 0.3750\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.1922 - acc: 0.937 - 0s 2ms/step - loss: 0.1346 - acc: 0.9688 - val_loss: 3.6992 - val_acc: 0.2500\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.1755 - acc: 0.937 - 0s 2ms/step - loss: 0.1123 - acc: 0.9688 - val_loss: 3.8504 - val_acc: 0.3750\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0588 - acc: 1.000 - 0s 2ms/step - loss: 0.0995 - acc: 0.9688 - val_loss: 4.0487 - val_acc: 0.3750\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0674 - acc: 0.968 - 0s 2ms/step - loss: 0.0869 - acc: 0.9531 - val_loss: 4.1805 - val_acc: 0.3750\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0756 - acc: 0.968 - 0s 2ms/step - loss: 0.0729 - acc: 0.9688 - val_loss: 3.9613 - val_acc: 0.2500\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0174 - acc: 1.000 - 0s 2ms/step - loss: 0.0562 - acc: 0.9844 - val_loss: 4.0883 - val_acc: 0.2500\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0441 - acc: 1.000 - 0s 2ms/step - loss: 0.0553 - acc: 0.9844 - val_loss: 4.6845 - val_acc: 0.3750\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0602 - acc: 0.968 - 0s 2ms/step - loss: 0.0558 - acc: 0.9688 - val_loss: 5.4848 - val_acc: 0.3750\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0712 - acc: 0.968 - 0s 2ms/step - loss: 0.0525 - acc: 0.9688 - val_loss: 5.1353 - val_acc: 0.3750\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0528 - acc: 0.968 - 0s 2ms/step - loss: 0.0330 - acc: 0.9844 - val_loss: 4.9454 - val_acc: 0.2500\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0262 - acc: 1.000 - 0s 2ms/step - loss: 0.0410 - acc: 0.9844 - val_loss: 4.8571 - val_acc: 0.2500\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0341 - acc: 0.968 - 0s 2ms/step - loss: 0.0492 - acc: 0.9688 - val_loss: 5.1298 - val_acc: 0.2500\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0668 - acc: 0.968 - 0s 2ms/step - loss: 0.0444 - acc: 0.9844 - val_loss: 5.0139 - val_acc: 0.2500\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0273 - acc: 0.968 - 0s 2ms/step - loss: 0.0309 - acc: 0.9688 - val_loss: 5.1958 - val_acc: 0.2500\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0238 - acc: 1.000 - 0s 2ms/step - loss: 0.0412 - acc: 0.9844 - val_loss: 5.2503 - val_acc: 0.2500\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.000 - 0s 2ms/step - loss: 0.0298 - acc: 0.9844 - val_loss: 5.6728 - val_acc: 0.3750\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0262 - acc: 0.968 - 0s 2ms/step - loss: 0.0253 - acc: 0.9844 - val_loss: 5.9322 - val_acc: 0.3750\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0133 - acc: 1.000 - 0s 2ms/step - loss: 0.0454 - acc: 0.9844 - val_loss: 5.9638 - val_acc: 0.3750\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0093 - acc: 1.000 - 0s 2ms/step - loss: 0.0324 - acc: 0.9844 - val_loss: 5.4188 - val_acc: 0.2500\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0452 - acc: 0.968 - 0s 2ms/step - loss: 0.0243 - acc: 0.9844 - val_loss: 4.9096 - val_acc: 0.2500\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0069 - acc: 1.000 - 0s 2ms/step - loss: 0.0635 - acc: 0.9844 - val_loss: 4.8444 - val_acc: 0.2500\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0991 - acc: 0.968 - 0s 2ms/step - loss: 0.0564 - acc: 0.9844 - val_loss: 5.3425 - val_acc: 0.2500\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0483 - acc: 0.968 - 0s 2ms/step - loss: 0.0253 - acc: 0.9844 - val_loss: 5.6888 - val_acc: 0.2500\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0744 - acc: 0.968 - 0s 2ms/step - loss: 0.0411 - acc: 0.9844 - val_loss: 5.6172 - val_acc: 0.2500\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0104 - acc: 1.000 - 0s 2ms/step - loss: 0.0307 - acc: 0.9844 - val_loss: 5.5409 - val_acc: 0.2500\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0296 - acc: 0.968 - 0s 2ms/step - loss: 0.0408 - acc: 0.9688 - val_loss: 5.2847 - val_acc: 0.2500\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0076 - acc: 1.000 - 0s 2ms/step - loss: 0.0435 - acc: 0.9844 - val_loss: 5.3168 - val_acc: 0.2500\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.000 - 0s 2ms/step - loss: 0.0288 - acc: 0.9844 - val_loss: 5.5566 - val_acc: 0.2500\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0241 - acc: 1.000 - 0s 2ms/step - loss: 0.0416 - acc: 0.9844 - val_loss: 5.8250 - val_acc: 0.2500\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0705 - acc: 0.968 - 0s 2ms/step - loss: 0.0403 - acc: 0.9844 - val_loss: 5.5507 - val_acc: 0.2500\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0113 - acc: 1.000 - 0s 2ms/step - loss: 0.0277 - acc: 0.9844 - val_loss: 5.3032 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0274 - acc: 0.968 - 0s 2ms/step - loss: 0.0365 - acc: 0.9688 - val_loss: 4.9712 - val_acc: 0.2500\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0538 - acc: 0.968 - 0s 2ms/step - loss: 0.0337 - acc: 0.9844 - val_loss: 5.0082 - val_acc: 0.2500\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0157 - acc: 1.000 - 0s 2ms/step - loss: 0.0277 - acc: 0.9844 - val_loss: 5.0807 - val_acc: 0.2500\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.968 - 0s 2ms/step - loss: 0.0242 - acc: 0.9844 - val_loss: 5.3068 - val_acc: 0.2500\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - 0s 2ms/step - loss: 0.0315 - acc: 0.9844 - val_loss: 5.4495 - val_acc: 0.2500\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0099 - acc: 1.000 - 0s 2ms/step - loss: 0.0290 - acc: 0.9844 - val_loss: 5.4587 - val_acc: 0.2500\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.968 - 0s 2ms/step - loss: 0.0242 - acc: 0.9844 - val_loss: 5.3309 - val_acc: 0.2500\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0580 - acc: 0.968 - 0s 2ms/step - loss: 0.0303 - acc: 0.9844 - val_loss: 5.3573 - val_acc: 0.2500\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.000 - 0s 2ms/step - loss: 0.0326 - acc: 0.9844 - val_loss: 5.4584 - val_acc: 0.2500\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0114 - acc: 1.000 - 0s 2ms/step - loss: 0.0243 - acc: 0.9844 - val_loss: 5.6364 - val_acc: 0.2500\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0207 - acc: 1.000 - 0s 2ms/step - loss: 0.0367 - acc: 0.9844 - val_loss: 5.8421 - val_acc: 0.2500\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0071 - acc: 1.000 - 0s 2ms/step - loss: 0.0400 - acc: 0.9844 - val_loss: 5.7848 - val_acc: 0.2500\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.000 - 0s 2ms/step - loss: 0.0298 - acc: 0.9844 - val_loss: 5.5390 - val_acc: 0.2500\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0182 - acc: 1.000 - 0s 2ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 5.3301 - val_acc: 0.2500\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - 0s 2ms/step - loss: 0.0324 - acc: 0.9844 - val_loss: 5.2152 - val_acc: 0.2500\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - 0s 2ms/step - loss: 0.0339 - acc: 0.9844 - val_loss: 5.2626 - val_acc: 0.2500\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - 0s 2ms/step - loss: 0.0244 - acc: 0.9844 - val_loss: 5.4094 - val_acc: 0.2500\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0193 - acc: 1.000 - 0s 2ms/step - loss: 0.0359 - acc: 0.9844 - val_loss: 5.5979 - val_acc: 0.2500\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0628 - acc: 0.968 - 0s 2ms/step - loss: 0.0319 - acc: 0.9844 - val_loss: 5.5485 - val_acc: 0.2500\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0483 - acc: 0.968 - 0s 2ms/step - loss: 0.0248 - acc: 0.9844 - val_loss: 5.4718 - val_acc: 0.2500\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 2ms/step - loss: 0.0287 - acc: 0.9844 - val_loss: 5.4781 - val_acc: 0.2500\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0104 - acc: 1.000 - 0s 2ms/step - loss: 0.0311 - acc: 0.9844 - val_loss: 5.5553 - val_acc: 0.2500\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0391 - acc: 0.968 - 0s 2ms/step - loss: 0.0333 - acc: 0.9688 - val_loss: 5.7304 - val_acc: 0.2500\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.968 - 0s 2ms/step - loss: 0.0261 - acc: 0.9844 - val_loss: 5.7336 - val_acc: 0.2500\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0134 - acc: 1.000 - 0s 2ms/step - loss: 0.0303 - acc: 0.9844 - val_loss: 5.7487 - val_acc: 0.2500\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0518 - acc: 0.968 - 0s 2ms/step - loss: 0.0265 - acc: 0.9844 - val_loss: 5.6244 - val_acc: 0.2500\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0204 - acc: 1.000 - 0s 2ms/step - loss: 0.0321 - acc: 0.9844 - val_loss: 5.5318 - val_acc: 0.2500\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.968 - 0s 2ms/step - loss: 0.0308 - acc: 0.9844 - val_loss: 5.6105 - val_acc: 0.2500\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0157 - acc: 1.000 - 0s 2ms/step - loss: 0.0255 - acc: 0.9844 - val_loss: 5.6696 - val_acc: 0.2500\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0454 - acc: 0.968 - 0s 2ms/step - loss: 0.0232 - acc: 0.9844 - val_loss: 5.8136 - val_acc: 0.2500\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0146 - acc: 1.000 - 0s 2ms/step - loss: 0.0321 - acc: 0.9844 - val_loss: 5.9136 - val_acc: 0.2500\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 9.4748e-04 - acc: 1.000 - 0s 2ms/step - loss: 0.0284 - acc: 0.9844 - val_loss: 5.8712 - val_acc: 0.2500\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - 0s 2ms/step - loss: 0.0232 - acc: 0.9844 - val_loss: 5.7740 - val_acc: 0.2500\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.968 - 0s 2ms/step - loss: 0.0228 - acc: 0.9844 - val_loss: 5.7696 - val_acc: 0.2500\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0472 - acc: 0.968 - 0s 2ms/step - loss: 0.0241 - acc: 0.9844 - val_loss: 5.8086 - val_acc: 0.2500\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0370 - acc: 0.968 - 0s 2ms/step - loss: 0.0278 - acc: 0.9844 - val_loss: 5.9342 - val_acc: 0.2500\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0260 - acc: 0.968 - 0s 2ms/step - loss: 0.0270 - acc: 0.9688 - val_loss: 6.0333 - val_acc: 0.2500\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0280 - acc: 0.968 - 0s 2ms/step - loss: 0.0265 - acc: 0.9688 - val_loss: 5.9813 - val_acc: 0.2500\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0247 - acc: 0.968 - 0s 2ms/step - loss: 0.0262 - acc: 0.9688 - val_loss: 6.0298 - val_acc: 0.2500\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0446 - acc: 0.968 - 0s 2ms/step - loss: 0.0227 - acc: 0.9844 - val_loss: 5.9918 - val_acc: 0.2500\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0213 - acc: 1.000 - 0s 2ms/step - loss: 0.0273 - acc: 0.9844 - val_loss: 5.9351 - val_acc: 0.2500\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0321 - acc: 0.968 - 0s 2ms/step - loss: 0.0274 - acc: 0.9688 - val_loss: 6.0158 - val_acc: 0.2500\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0206 - acc: 1.000 - 0s 2ms/step - loss: 0.0268 - acc: 0.9844 - val_loss: 6.0744 - val_acc: 0.2500\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0458 - acc: 0.968 - 0s 2ms/step - loss: 0.0233 - acc: 0.9844 - val_loss: 6.0330 - val_acc: 0.2500\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0215 - acc: 1.000 - 0s 2ms/step - loss: 0.0282 - acc: 0.9844 - val_loss: 5.9766 - val_acc: 0.2500\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.4619e-04 - acc: 1.000 - 0s 2ms/step - loss: 0.0244 - acc: 0.9844 - val_loss: 6.0300 - val_acc: 0.2500\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0158 - acc: 1.000 - 0s 2ms/step - loss: 0.0238 - acc: 0.9844 - val_loss: 6.1017 - val_acc: 0.2500\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0440 - acc: 0.968 - 0s 2ms/step - loss: 0.0223 - acc: 0.9844 - val_loss: 6.2249 - val_acc: 0.2500\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0363 - acc: 0.968 - 0s 2ms/step - loss: 0.0255 - acc: 0.9844 - val_loss: 6.2329 - val_acc: 0.2500\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.4531e-04 - acc: 1.000 - 0s 2ms/step - loss: 0.0246 - acc: 0.9844 - val_loss: 6.2355 - val_acc: 0.2500\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0324 - acc: 0.968 - 0s 2ms/step - loss: 0.0285 - acc: 0.9688 - val_loss: 6.1221 - val_acc: 0.2500\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 7.1983e-04 - acc: 1.000 - 0s 2ms/step - loss: 0.0233 - acc: 0.9844 - val_loss: 6.1089 - val_acc: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a217160da0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_model.fit(ethnicity_train_x,ethnicity_train_y,epochs=100,batch_size=32,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_model.save('ethnicity_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict={\n",
    "    'angry':0,\n",
    "    'happy':1,\n",
    "    'neutral':2,\n",
    "    'sad':3\n",
    "}\n",
    "emotions_train_x = []\n",
    "emotions_train_y=[]\n",
    "\n",
    "for item in os.listdir('./dataset/emotions'):\n",
    "    for p in os.listdir('./dataset/emotions/'+str(item)):\n",
    "        try:\n",
    "            image = keras.preprocessing.image.load_img('./dataset/emotions/'+str(item)+\"/\"+str(p),target_size=(70,70))\n",
    "            image = keras.preprocessing.image.img_to_array(image)\n",
    "            image = image/255\n",
    "            emotions_train_x.append(image)\n",
    "            emotions_train_y.append(emotion_dict[item])\n",
    "        except:\n",
    "            continue\n",
    "emotions_train_x = np.asarray(emotions_train_x)\n",
    "emotions_train_y = np.asarray(emotions_train_y)\n",
    "\n",
    "emotions_train_y=keras.utils.to_categorical(emotions_train_y)\n",
    "\n",
    "emotions_train_x, emotions_train_y= shuffle(emotions_train_x,emotions_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(70, 70, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "emotions_model = Sequential()\n",
    "\n",
    "#Convolution layer 1\n",
    "emotions_model.add(Conv2D(32,3,3,input_shape=(70,70,3),activation='relu'))\n",
    "emotions_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Convolution layer 2\n",
    "emotions_model.add(Conv2D(64,3,3,activation='relu'))\n",
    "emotions_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Flattening \n",
    "emotions_model.add(Flatten())\n",
    "#Feeding into fully Connected layers\n",
    "emotions_model.add(Dense(128,activation='relu'))\n",
    "emotions_model.add(Dense(64,activation='relu'))\n",
    "#output layer\n",
    "emotions_model.add(Dense(emotions_train_y.shape[1],activation='softmax')) \n",
    "emotions_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 8 samples\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.3849 - acc: 0.125 - ETA: 0s - loss: 1.4999 - acc: 0.187 - 1s 15ms/step - loss: 1.4581 - acc: 0.2206 - val_loss: 1.0327 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 2.0105 - acc: 0.375 - ETA: 0s - loss: 1.6178 - acc: 0.453 - 0s 2ms/step - loss: 1.5826 - acc: 0.4706 - val_loss: 1.1434 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.2799 - acc: 0.468 - ETA: 0s - loss: 1.1943 - acc: 0.453 - 0s 2ms/step - loss: 1.1835 - acc: 0.4559 - val_loss: 1.2154 - val_acc: 0.1250\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.2177 - acc: 0.312 - ETA: 0s - loss: 1.1468 - acc: 0.359 - 0s 2ms/step - loss: 1.1666 - acc: 0.3529 - val_loss: 1.1704 - val_acc: 0.2500\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.3175 - acc: 0.218 - ETA: 0s - loss: 1.1371 - acc: 0.484 - 0s 2ms/step - loss: 1.1431 - acc: 0.4706 - val_loss: 1.0779 - val_acc: 0.7500\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0438 - acc: 0.687 - ETA: 0s - loss: 1.0679 - acc: 0.593 - 0s 2ms/step - loss: 1.1006 - acc: 0.5735 - val_loss: 1.0480 - val_acc: 0.8750\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0298 - acc: 0.593 - ETA: 0s - loss: 1.0713 - acc: 0.593 - 0s 2ms/step - loss: 1.0612 - acc: 0.5882 - val_loss: 1.1396 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0616 - acc: 0.531 - ETA: 0s - loss: 1.0101 - acc: 0.609 - 0s 2ms/step - loss: 1.0266 - acc: 0.5882 - val_loss: 1.0984 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.7724 - acc: 0.750 - ETA: 0s - loss: 0.9697 - acc: 0.640 - 0s 2ms/step - loss: 0.9887 - acc: 0.6471 - val_loss: 1.0004 - val_acc: 0.7500\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0238 - acc: 0.562 - ETA: 0s - loss: 0.9081 - acc: 0.703 - 0s 2ms/step - loss: 0.8985 - acc: 0.7059 - val_loss: 1.2220 - val_acc: 0.3750\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.8104 - acc: 0.656 - ETA: 0s - loss: 0.9107 - acc: 0.562 - 0s 2ms/step - loss: 0.8867 - acc: 0.5882 - val_loss: 1.1689 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.6994 - acc: 0.718 - ETA: 0s - loss: 0.7560 - acc: 0.671 - 0s 2ms/step - loss: 0.7702 - acc: 0.6471 - val_loss: 0.8044 - val_acc: 0.7500\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.7659 - acc: 0.593 - ETA: 0s - loss: 0.7278 - acc: 0.671 - 0s 2ms/step - loss: 0.7415 - acc: 0.6765 - val_loss: 1.2850 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.7475 - acc: 0.718 - ETA: 0s - loss: 0.6997 - acc: 0.750 - 0s 2ms/step - loss: 0.6752 - acc: 0.7647 - val_loss: 1.4768 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.3820 - acc: 0.843 - ETA: 0s - loss: 0.6983 - acc: 0.656 - 0s 2ms/step - loss: 0.6781 - acc: 0.6765 - val_loss: 0.9759 - val_acc: 0.7500\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.8570 - acc: 0.625 - ETA: 0s - loss: 0.7239 - acc: 0.687 - 0s 2ms/step - loss: 0.7015 - acc: 0.7059 - val_loss: 1.3636 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.5174 - acc: 0.781 - ETA: 0s - loss: 0.5946 - acc: 0.750 - 0s 2ms/step - loss: 0.5857 - acc: 0.7500 - val_loss: 1.6291 - val_acc: 0.2500\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.6658 - acc: 0.781 - ETA: 0s - loss: 0.5401 - acc: 0.828 - 0s 2ms/step - loss: 0.5434 - acc: 0.8235 - val_loss: 1.0669 - val_acc: 0.7500\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.5117 - acc: 0.781 - ETA: 0s - loss: 0.5008 - acc: 0.812 - 0s 2ms/step - loss: 0.4770 - acc: 0.8235 - val_loss: 1.1552 - val_acc: 0.7500\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.3420 - acc: 0.906 - ETA: 0s - loss: 0.3961 - acc: 0.843 - 0s 2ms/step - loss: 0.3843 - acc: 0.8529 - val_loss: 1.6033 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2592 - acc: 0.937 - ETA: 0s - loss: 0.2951 - acc: 0.937 - 0s 2ms/step - loss: 0.3077 - acc: 0.9118 - val_loss: 1.4124 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1517 - acc: 1.000 - ETA: 0s - loss: 0.2619 - acc: 0.937 - 0s 2ms/step - loss: 0.2493 - acc: 0.9412 - val_loss: 1.6244 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2471 - acc: 0.906 - ETA: 0s - loss: 0.2145 - acc: 0.937 - 0s 2ms/step - loss: 0.2095 - acc: 0.9412 - val_loss: 1.5984 - val_acc: 0.6250\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1993 - acc: 0.968 - ETA: 0s - loss: 0.1467 - acc: 0.968 - 0s 2ms/step - loss: 0.1741 - acc: 0.9412 - val_loss: 1.3880 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2156 - acc: 0.906 - ETA: 0s - loss: 0.2470 - acc: 0.875 - 0s 2ms/step - loss: 0.2395 - acc: 0.8824 - val_loss: 1.3785 - val_acc: 0.6250\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1154 - acc: 1.000 - ETA: 0s - loss: 0.1219 - acc: 1.000 - 0s 2ms/step - loss: 0.1196 - acc: 1.0000 - val_loss: 1.7351 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1205 - acc: 1.000 - ETA: 0s - loss: 0.1224 - acc: 0.984 - 0s 2ms/step - loss: 0.1200 - acc: 0.9853 - val_loss: 1.5535 - val_acc: 0.7500\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1099 - acc: 0.968 - ETA: 0s - loss: 0.0907 - acc: 0.984 - 0s 2ms/step - loss: 0.0971 - acc: 0.9853 - val_loss: 1.5431 - val_acc: 0.7500\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1287 - acc: 0.968 - ETA: 0s - loss: 0.0993 - acc: 0.984 - 0s 2ms/step - loss: 0.0941 - acc: 0.9853 - val_loss: 1.6669 - val_acc: 0.7500\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0540 - acc: 1.000 - ETA: 0s - loss: 0.0600 - acc: 1.000 - 0s 2ms/step - loss: 0.0593 - acc: 1.0000 - val_loss: 1.8016 - val_acc: 0.6250\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0384 - acc: 1.000 - ETA: 0s - loss: 0.0406 - acc: 1.000 - 0s 2ms/step - loss: 0.0421 - acc: 1.0000 - val_loss: 1.7763 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0154 - acc: 1.000 - ETA: 0s - loss: 0.0232 - acc: 1.000 - 0s 2ms/step - loss: 0.0250 - acc: 1.0000 - val_loss: 1.8452 - val_acc: 0.7500\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0305 - acc: 1.000 - ETA: 0s - loss: 0.0331 - acc: 1.000 - 0s 2ms/step - loss: 0.0317 - acc: 1.0000 - val_loss: 2.0052 - val_acc: 0.7500\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0119 - acc: 1.000 - ETA: 0s - loss: 0.0190 - acc: 1.000 - 0s 2ms/step - loss: 0.0182 - acc: 1.0000 - val_loss: 2.2944 - val_acc: 0.6250\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0201 - acc: 1.000 - ETA: 0s - loss: 0.0143 - acc: 1.000 - 0s 2ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 2.5435 - val_acc: 0.6250\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0157 - acc: 1.000 - ETA: 0s - loss: 0.0146 - acc: 1.000 - 0s 2ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 2.3986 - val_acc: 0.6250\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0098 - acc: 1.000 - ETA: 0s - loss: 0.0084 - acc: 1.000 - 0s 2ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.1294 - val_acc: 0.7500\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0040 - acc: 1.000 - ETA: 0s - loss: 0.0045 - acc: 1.000 - 0s 2ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 1.9920 - val_acc: 0.7500\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0062 - acc: 1.000 - 0s 2ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.9941 - val_acc: 0.7500\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0052 - acc: 1.000 - 0s 2ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.1171 - val_acc: 0.7500\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - 0s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.2929 - val_acc: 0.6250\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0045 - acc: 1.000 - ETA: 0s - loss: 0.0032 - acc: 1.000 - 0s 2ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 2.4386 - val_acc: 0.6250\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0027 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - 0s 2ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 2.5156 - val_acc: 0.6250\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0027 - acc: 1.000 - 0s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.5377 - val_acc: 0.6250\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0024 - acc: 1.000 - 0s 2ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.5388 - val_acc: 0.7500\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 2ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.5333 - val_acc: 0.7500\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - 0s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.5366 - val_acc: 0.7500\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0021 - acc: 1.000 - 0s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.5600 - val_acc: 0.7500\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - 0s 2ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.6033 - val_acc: 0.7500\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.6479 - val_acc: 0.6250\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.6753 - val_acc: 0.6250\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - 0s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.6826 - val_acc: 0.6250\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - 0s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.6685 - val_acc: 0.6250\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 7.8018e-04 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.0000    - 0s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.6327 - val_acc: 0.7500\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - 0s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.5996 - val_acc: 0.7500\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - 0s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.5982 - val_acc: 0.7500\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - 0s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.6368 - val_acc: 0.7500\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - 0s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.7183 - val_acc: 0.7500\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - 0s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.7913 - val_acc: 0.6250\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - 0s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.8439 - val_acc: 0.6250\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 9.9543e-04 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.0000    - 0s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.8656 - val_acc: 0.6250\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 6.4343e-04 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.0000    - 0s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.8580 - val_acc: 0.6250\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - 0s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.8317 - val_acc: 0.6250\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 7.4982e-04 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.0000    - 0s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.8021 - val_acc: 0.6250\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 9.9063e-04 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.0000    - 0s 2ms/step - loss: 9.5623e-04 - acc: 1.0000 - val_loss: 2.7731 - val_acc: 0.7500\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 9.2058e-04 - acc: 1.000 - ETA: 0s - loss: 9.5262e-04 - acc: 1.000 - 0s 2ms/step - loss: 9.4064e-04 - acc: 1.0000 - val_loss: 2.7583 - val_acc: 0.7500\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 6.7110e-04 - acc: 1.000 - ETA: 0s - loss: 9.5214e-04 - acc: 1.000 - 0s 2ms/step - loss: 9.2616e-04 - acc: 1.0000 - val_loss: 2.7523 - val_acc: 0.7500\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 9.1232e-04 - acc: 1.000 - ETA: 0s - loss: 9.4622e-04 - acc: 1.000 - 0s 2ms/step - loss: 9.1649e-04 - acc: 1.0000 - val_loss: 2.7542 - val_acc: 0.7500\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 6.5643e-04 - acc: 1.000 - ETA: 0s - loss: 7.4810e-04 - acc: 1.000 - 0s 2ms/step - loss: 8.8380e-04 - acc: 1.0000 - val_loss: 2.7684 - val_acc: 0.7500\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 8.8093e-04 - acc: 1.000 - ETA: 0s - loss: 8.7973e-04 - acc: 1.000 - 0s 2ms/step - loss: 8.3768e-04 - acc: 1.0000 - val_loss: 2.7872 - val_acc: 0.7500\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 5.2546e-04 - acc: 1.000 - ETA: 0s - loss: 7.0988e-04 - acc: 1.000 - 0s 2ms/step - loss: 7.9679e-04 - acc: 1.0000 - val_loss: 2.8044 - val_acc: 0.7500\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 7.2683e-04 - acc: 1.000 - ETA: 0s - loss: 7.4263e-04 - acc: 1.000 - 0s 2ms/step - loss: 7.8233e-04 - acc: 1.0000 - val_loss: 2.8165 - val_acc: 0.7500\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 7.2739e-04 - acc: 1.000 - ETA: 0s - loss: 7.9978e-04 - acc: 1.000 - 0s 2ms/step - loss: 7.8134e-04 - acc: 1.0000 - val_loss: 2.8263 - val_acc: 0.7500\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 9.1305e-04 - acc: 1.000 - ETA: 0s - loss: 7.9328e-04 - acc: 1.000 - 0s 2ms/step - loss: 7.7362e-04 - acc: 1.0000 - val_loss: 2.8333 - val_acc: 0.7500\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 7.5243e-04 - acc: 1.000 - ETA: 0s - loss: 7.7928e-04 - acc: 1.000 - 0s 2ms/step - loss: 7.6055e-04 - acc: 1.0000 - val_loss: 2.8515 - val_acc: 0.7500\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 5.4143e-04 - acc: 1.000 - ETA: 0s - loss: 6.8352e-04 - acc: 1.000 - 0s 2ms/step - loss: 7.3515e-04 - acc: 1.0000 - val_loss: 2.8746 - val_acc: 0.7500\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 6.4183e-04 - acc: 1.000 - ETA: 0s - loss: 7.1212e-04 - acc: 1.000 - 0s 2ms/step - loss: 7.0928e-04 - acc: 1.0000 - val_loss: 2.8919 - val_acc: 0.7500\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - ETA: 0s - loss: 8.0423e-04 - acc: 1.000 - ETA: 0s - loss: 7.0228e-04 - acc: 1.000 - 0s 2ms/step - loss: 6.8410e-04 - acc: 1.0000 - val_loss: 2.8989 - val_acc: 0.7500\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 9.3015e-04 - acc: 1.000 - ETA: 0s - loss: 6.8432e-04 - acc: 1.000 - 0s 2ms/step - loss: 6.6170e-04 - acc: 1.0000 - val_loss: 2.9121 - val_acc: 0.7500\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 7.1406e-04 - acc: 1.000 - ETA: 0s - loss: 6.6046e-04 - acc: 1.000 - 0s 2ms/step - loss: 6.4247e-04 - acc: 1.0000 - val_loss: 2.9246 - val_acc: 0.7500\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 4.8776e-04 - acc: 1.000 - ETA: 0s - loss: 6.4326e-04 - acc: 1.000 - 0s 2ms/step - loss: 6.2281e-04 - acc: 1.0000 - val_loss: 2.9324 - val_acc: 0.7500\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 6.2067e-04 - acc: 1.000 - ETA: 0s - loss: 6.0428e-04 - acc: 1.000 - 0s 2ms/step - loss: 6.1133e-04 - acc: 1.0000 - val_loss: 2.9359 - val_acc: 0.7500\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 7.3460e-04 - acc: 1.000 - ETA: 0s - loss: 5.9016e-04 - acc: 1.000 - 0s 2ms/step - loss: 5.9601e-04 - acc: 1.0000 - val_loss: 2.9347 - val_acc: 0.7500\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 7.7644e-04 - acc: 1.000 - ETA: 0s - loss: 5.5791e-04 - acc: 1.000 - 0s 2ms/step - loss: 5.8026e-04 - acc: 1.0000 - val_loss: 2.9392 - val_acc: 0.7500\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 3.6322e-04 - acc: 1.000 - ETA: 0s - loss: 5.8548e-04 - acc: 1.000 - 0s 2ms/step - loss: 5.6907e-04 - acc: 1.0000 - val_loss: 2.9397 - val_acc: 0.7500\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 3.5437e-04 - acc: 1.000 - ETA: 0s - loss: 5.6383e-04 - acc: 1.000 - 0s 2ms/step - loss: 5.5737e-04 - acc: 1.0000 - val_loss: 2.9426 - val_acc: 0.7500\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 4.4517e-04 - acc: 1.000 - ETA: 0s - loss: 5.4476e-04 - acc: 1.000 - 0s 2ms/step - loss: 5.4522e-04 - acc: 1.0000 - val_loss: 2.9466 - val_acc: 0.7500\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 3.9324e-04 - acc: 1.000 - ETA: 0s - loss: 4.6780e-04 - acc: 1.000 - 0s 2ms/step - loss: 5.3651e-04 - acc: 1.0000 - val_loss: 2.9490 - val_acc: 0.7500\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 4.0404e-04 - acc: 1.000 - ETA: 0s - loss: 5.3677e-04 - acc: 1.000 - 0s 2ms/step - loss: 5.1977e-04 - acc: 1.0000 - val_loss: 2.9555 - val_acc: 0.7500\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 4.3126e-04 - acc: 1.000 - ETA: 0s - loss: 5.1967e-04 - acc: 1.000 - 0s 2ms/step - loss: 5.0711e-04 - acc: 1.0000 - val_loss: 2.9632 - val_acc: 0.7500\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 5.1526e-04 - acc: 1.000 - ETA: 0s - loss: 5.1681e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.9896e-04 - acc: 1.0000 - val_loss: 2.9688 - val_acc: 0.7500\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 3.5121e-04 - acc: 1.000 - ETA: 0s - loss: 4.8344e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.8832e-04 - acc: 1.0000 - val_loss: 2.9790 - val_acc: 0.7500\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 5.5459e-04 - acc: 1.000 - ETA: 0s - loss: 4.8927e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.7952e-04 - acc: 1.0000 - val_loss: 2.9865 - val_acc: 0.7500\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 5.1199e-04 - acc: 1.000 - ETA: 0s - loss: 4.8711e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.7345e-04 - acc: 1.0000 - val_loss: 2.9997 - val_acc: 0.7500\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 5.0806e-04 - acc: 1.000 - ETA: 0s - loss: 4.6619e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.6481e-04 - acc: 1.0000 - val_loss: 3.0105 - val_acc: 0.7500\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 3.4700e-04 - acc: 1.000 - ETA: 0s - loss: 4.7713e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.5494e-04 - acc: 1.0000 - val_loss: 3.0188 - val_acc: 0.7500\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 4.5593e-04 - acc: 1.000 - ETA: 0s - loss: 4.5512e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.4624e-04 - acc: 1.0000 - val_loss: 3.0283 - val_acc: 0.7500\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 5.1554e-04 - acc: 1.000 - ETA: 0s - loss: 4.5991e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.3763e-04 - acc: 1.0000 - val_loss: 3.0374 - val_acc: 0.7500\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 6.8064e-04 - acc: 1.000 - ETA: 0s - loss: 4.4617e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.2970e-04 - acc: 1.0000 - val_loss: 3.0445 - val_acc: 0.7500\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 4.1442e-04 - acc: 1.000 - ETA: 0s - loss: 4.2866e-04 - acc: 1.000 - 0s 2ms/step - loss: 4.2099e-04 - acc: 1.0000 - val_loss: 3.0512 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2c4dbb390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_model.fit(emotions_train_x,emotions_train_y,epochs=100,batch_size=32,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_model.save('emotions_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
